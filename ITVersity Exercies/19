# Instructions
# Get number of companies who filed LCAs for each year

# Data Description
# h1b data with ascii null "\0" as delimiter is available in HDFS

# h1b data information:

# HDFS Location: /public/h1b/h1b_data_noheader
# Fields: 
# ID, CASE_STATUS, EMPLOYER_NAME, SOC_NAME, JOB_TITLE, FULL_TIME_POSITION, PREVAILING_WAGE, YEAR, WORKSITE, LONGITUDE, LATITUDE
# Use EMPLOYER_NAME as the criteria to identify the company name to get number of companies
# YEAR is 8th field
# There are some LCAs for which YEAR is NA, ignore those records
# Output Requirements
# File Format: text
# Delimiter: tab character "\t"
# Output Field Order: year, lca_count
# Place the output files in the HDFS directory
# /user/`whoami`/problem19/solution/
# Replace `whoami` with your OS user name
# End of Problem

spark-shell --master yarn --conf spark.ui.port=15214 --num-executors 4 --executor-memory 3G --executor-cores 2

val data = sc.textFile("/public/h1b/h1b_data_noheader")

val dataMap = data.filter(rec=> rec.split("\0")(7) != "NA").map(rec=> {
(rec.split("\0")(7).toInt,rec.split("\0")(2))
}).toDF("Year","Company")

dataMap.registerTempTable("data_lca_companies")

val query = sqlContext.sql("select Year as year, count(1) as lca_count from data_lca_companies group by Company,Year")

query.coalesce(1).rdd.map(rec=> rec.mkString("\t")).saveAsTextFile("/user/chaitanyapolipalli/Practice_exam/problem19/solution/")
